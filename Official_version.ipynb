{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Official_version.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X-odxHcrG6MK",
        "BkXtwKEiHan_",
        "5wFRtXlQHg-P"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3ed79b9456f4fda847357b6454e570f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c3e77aae90149a4824c5f236cca5be2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8ee8b5987fc4461a2f2931312f614d4",
              "IPY_MODEL_e043a8b2d88346afbddabbd78d78ef5a"
            ]
          }
        },
        "0c3e77aae90149a4824c5f236cca5be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8ee8b5987fc4461a2f2931312f614d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_701a55ef7b0d4dcc9a3a88c4b1553c37",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 864,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 864,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbaef8a43c2c45b49ff7fc86bf1810df"
          }
        },
        "e043a8b2d88346afbddabbd78d78ef5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50ef29bd333a4cb6899ba76739df4e7b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 864/864 [00:28&lt;00:00, 30.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2f4ee74eeb44dfe80748940aa192ca2"
          }
        },
        "701a55ef7b0d4dcc9a3a88c4b1553c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbaef8a43c2c45b49ff7fc86bf1810df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50ef29bd333a4cb6899ba76739df4e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2f4ee74eeb44dfe80748940aa192ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng1aVKfsG1zF"
      },
      "source": [
        "# Start and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHEZKUbj9jcD",
        "outputId": "acfc5d3a-85f5-4ebc-c7f4-9b8316d15165"
      },
      "source": [
        "# Техно-библиотеки без которых никуда\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from tqdm.notebook import tqdm, trange\n",
        "import numpy as np\n",
        "\n",
        "# Компьютерное зрение и визуализация\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import albumentations as A\n",
        "\n",
        "# Нейросетки\n",
        "import torch\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "\n",
        "# Диск\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Сажаем на свой диск\n",
        "%cd '/content/drive/MyDrive/DataScience[Практика]/Цифровой прорыв/'\n",
        "\n",
        "# DEVICE = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = 'cpu'\n",
        "classifier_weights = 'checkpoints/ResNet101-best.pth'\n",
        "detector_weights = 'checkpoints/bear_detect_model.pth'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/DataScience[Практика]/Цифровой прорыв\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjmeMsHEAI6j"
      },
      "source": [
        "def to_torch_image(image):\n",
        "    image = np.moveaxis(image, -1, 0)\n",
        "    return torch.from_numpy(image)\n",
        "\n",
        "def to_numpy_image(image):\n",
        "    image = np.array(image)\n",
        "    image = np.moveaxis(image, 0, -1)\n",
        "    return image\n",
        "\n",
        "def draw_bboxes(image, bboxes, thickness=5):\n",
        "    for bear in bboxes:\n",
        "        x1, y1, x2, y2 = bear\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), thickness)\n",
        "    return image\n",
        "\n",
        "normalize = A.Compose([A.RandomCrop(224, 224), \n",
        "                       A.Normalize()], bbox_params={'format':'pascal_voc'})"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-odxHcrG6MK"
      },
      "source": [
        "# Classificator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fedfl_XD99xO",
        "outputId": "00e23a2a-42b7-4b69-a87b-c03d24b8d042"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        model = models.resnet101(pretrained=True)\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in model.layer4.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        self.model = model\n",
        "        self.end_layer = nn.Sequential(\n",
        "            nn.Linear(1000, 128),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.end_layer(self.model(X))\n",
        "    \n",
        "    def __call__(self, X):\n",
        "        return self.forward(X)\n",
        "\n",
        "classifier = ResNet().to(device)\n",
        "classifier.load_state_dict(torch.load(classifier_weights))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53HGl_KSHYyX"
      },
      "source": [
        "# Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxyTTYPG-Cl-"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "# workaround: install old version of pytorch since detectron2 hasn't released packages for pytorch 1.9 (issue: https://github.com/facebookresearch/detectron2/issues/3158)\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install detectron2 that matches pytorch 1.8\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "assert torch.__version__.startswith(\"1.8\")   # please manually install torch 1.8 if Colab changes its default version\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "clear_output()\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.engine import DefaultTrainer\n",
        "clear_output()\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "cfg.MODEL.WEIGHTS = detector_weights  # path to the model we just trained\n",
        "cfg.MODEL.DEVICE = 'cpu'\n",
        "detector = DefaultPredictor(cfg)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkXtwKEiHan_"
      },
      "source": [
        "# Data prepairing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNR0xjWG_I8N"
      },
      "source": [
        "class Data:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.length = len(data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        if isinstance(self.data, str): # Путь до картнки\n",
        "            image = cv2.imread(self.data[i])\n",
        "        elif isinstance(self.data, torch.Tensor):\n",
        "            if len(self.data.shape) == 3: # Картинка\n",
        "                image = to_numpy_image(self.data[i])\n",
        "            elif len(self.data.shape) == 4: # Батч картинок\n",
        "                image = to_numpy_image(self.data[i])\n",
        "        elif isinstance(self.data, list):\n",
        "            if isinstance(self.data[i], str):\n",
        "                image = cv2.imread(self.data[i]) # Если путь\n",
        "            else:\n",
        "                image = self.data[i]\n",
        "        else:\n",
        "            image = self.data[i]\n",
        "        return image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __iter__(self):\n",
        "        self.n = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        x = self.__getitem__(self.n)\n",
        "        self.n += 1\n",
        "        if self.n < self.length:\n",
        "            return x\n",
        "        raise StopIteration\n",
        "\n",
        "\n",
        "class Cutter:\n",
        "    def __init__(self, data, size=224, step_size=200):\n",
        "        self.size = size\n",
        "        self.step_size = step_size\n",
        "        self.data = data\n",
        "        self.length = len(self.data)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        image = self.data[i]\n",
        "        images = []\n",
        "        for r in range(0, image.shape[0], self.step_size):\n",
        "            for c in range(0, image.shape[1], self.step_size):\n",
        "                new_image = image[r:r + self.size, c:c + self.size, :]\n",
        "                if new_image.shape == (self.size, self.size, 3):\n",
        "                    images.append([new_image, [c, r, c, r]])\n",
        "        return images\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.n = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        x = self.__getitem__(self.n)\n",
        "        self.n += 1\n",
        "        if self.n < self.length:\n",
        "            return x\n",
        "        raise StopIteration"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoU4fjTkAehR"
      },
      "source": [
        "class Predictor:\n",
        "    def __init__(self, model, raw_data):\n",
        "        data = Data(raw_data)\n",
        "        self.model = model\n",
        "        self.cutter = Cutter(data)\n",
        "        self.length = len(self.cutter)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.model.eval()\n",
        "        images =  self.cutter[i]\n",
        "        for cutted_image in tqdm(images):\n",
        "            image, coords = cutted_image\n",
        "            preds = self.model(image)\n",
        "            if not isinstance(preds, list):\n",
        "                output = preds[\"instances\"][preds['instances'].get_fields()['scores'] > 0.9]\n",
        "                preds = list(list(output.get_fields()['pred_boxes']))\n",
        "                preds = [list(map(lambda x: x.item(), list(preds[i]))) for i in range(len(preds))]\n",
        "                coords = np.array(coords)\n",
        "                coords = np.array([int(coords[1]), int(coords[0]),\n",
        "                                int(coords[1]), int(coords[0])])\n",
        "                preds = np.array(preds, dtype=np.int)\n",
        "\n",
        "            if len(preds) > 0:\n",
        "                preds = preds + coords\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __iter__(self):\n",
        "        self.n = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        x = self.__getitem__(self.n)\n",
        "        self.n += 1\n",
        "        if self.n < self.length:\n",
        "            return x\n",
        "        raise StopIteration"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wFRtXlQHg-P"
      },
      "source": [
        "# BearCatcher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFbP8vtcAW6o"
      },
      "source": [
        "class BearCatcher(nn.Module):\n",
        "    def __init__(self, classifier, detector):\n",
        "        super().__init__()\n",
        "        self.classifier = classifier\n",
        "        self.detector = detector\n",
        "    \n",
        "    def forward(self, X):\n",
        "        detection = []\n",
        "        normed = normalize(image=X, bboxes=[])['image']\n",
        "        z = to_torch_image(normed)\n",
        "        z = z.unsqueeze(0).to(device)\n",
        "        z = self.classifier(z)\n",
        "        if not (torch.sigmoid(z) > 0.95):\n",
        "            return detection\n",
        "        X = np.array(X, dtype=np.uint8)\n",
        "        detection = self.detector(X)\n",
        "        return detection\n",
        "\n",
        "\n",
        "    def __call__(self, X):\n",
        "        return self.forward(X)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGrtt2L3HnaK"
      },
      "source": [
        "# Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2QhZDKcA7h7"
      },
      "source": [
        "model = BearCatcher(classifier, detector).to(device)\n",
        "clear_output()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up1VkEUKA8Og"
      },
      "source": [
        "images = [cv2.imread('data/images/_2016-05-12 14-20-10_2145_2R.JPG')]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e3ed79b9456f4fda847357b6454e570f",
            "0c3e77aae90149a4824c5f236cca5be2",
            "f8ee8b5987fc4461a2f2931312f614d4",
            "e043a8b2d88346afbddabbd78d78ef5a",
            "701a55ef7b0d4dcc9a3a88c4b1553c37",
            "bbaef8a43c2c45b49ff7fc86bf1810df",
            "50ef29bd333a4cb6899ba76739df4e7b",
            "b2f4ee74eeb44dfe80748940aa192ca2"
          ]
        },
        "id": "9nnlSA8eEPJp",
        "outputId": "aa021c8e-818f-40bf-f896-82272dd4d211"
      },
      "source": [
        "predictor = Predictor(model, images)\n",
        "for image in predictor:\n",
        "    print(image.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3ed79b9456f4fda847357b6454e570f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=864.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kDUgBjI_bKj"
      },
      "source": [
        "torch.save(model.state_dict(), 'checkpoints/BearCatcher.pth')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFNikvomBRuY"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(model, open('checkpoints/BearCatcher.pkl', 'wb'))"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}